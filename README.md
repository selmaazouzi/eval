# Generate Exam EVAL API 
Generate Exam EVAL API

<hr>

## `Clone repository`
```bash
git clone https://git.norsys-afrique.dev/ecole-technomacker2024/stscodinhub/generate-exam-syscodinghub.git
```

<hr>

## `Set up environment`
### Install `virtualenv`
```bash
pip install virtualenv
```
### Change current directory to `generate-exam-syscodinghub`
```bash
cd generate-exam-syscodinghub
```
### Create python `virtual environment`
```bash
python -m venv venv
```
### Activate it
- `Windows`
```bash
venv\Scripts\activate
```
- `Linux`
```bash
source venv/Scripts/activate
```
- `PowerShell`
no scripts like the activate script are allowed to be executed so you need to run PowerShell as `admin` and change `ExecutionPolicy` to `AllSigned` then type `A` to `Always run` `the command is under` in the end use `the command above` to activate virtual environment
```bash
Set-ExecutionPolicy AllSigned
```
### Install `virtualenv requirements`
```bash
pip install -r requirements.txt
```
### Run the app
```bash
python run.py
```

# Guide d‚Äôinstallation et de configuration ‚Äì Application RAG (Ollama + OpenRouter)

Ce guide explique comment installer toutes les d√©pendances, configurer Ollama, pr√©parer OpenRouter et lancer l‚Äôapplication.

---

## 1. Installer les d√©pendances Python

Dans un terminal (**Linux**) ou un **PowerShell**/**CMD** (**Windows**), ex√©cutez :

### Installation de PyTorch (version CPU uniquement)

```bash
pip install --no-cache-dir torch==2.3.1+cpu --index-url https://download.pytorch.org/whl/cpu

```
### Installation des autres biblioth√®ques n√©cessaires

```bash
pip install \
  langchain==0.3.26 \
  langchain-huggingface==0.3.0 \
  sentence-transformers==5.0.0 \
  transformers==4.53.1 \
  faiss-cpu==1.11.0 \
  python-dotenv==1.1.1 \
  langchain_community \
  jsonschema
```

 Ici, **PyTorch** est install√© en version **CPU** uniquement pour √©viter le t√©l√©chargement des biblioth√®ques GPU inutiles.

---

## 2. Installer Ollama

### üîπ Sur **Windows**
1. T√©l√©chargez le fichier `.msi` depuis :  
    [https://ollama.com/download](https://ollama.com/download)
2. Installez-le, puis ouvrez **PowerShell** ou **CMD** et v√©rifiez :
```bash
ollama --version
```
3. D√©marrez le serveur Ollama :
```bash
ollama serve
```

---

### üî∏ Sur **Linux**
1. Installez Ollama :
```bash
curl -fsSL https://ollama.com/install.sh | sh
```
2. D√©marrez le serveur Ollama :
```bash
ollama serve
```

---

##  3. T√©l√©charger le mod√®le Mistral

Ouvrez **un nouveau terminal** et lancez :
```bash
ollama run mistral
```

Cela t√©l√©charge et pr√©pare le mod√®le `mistral:latest` (~4 Go).

---

## 4. Configurer OpenRouter

### 1. Cr√©er un compte OpenRouter
- Rendez-vous sur : [https://openrouter.ai](https://openrouter.ai)
- Cr√©ez un compte.

---

### 2. G√©n√©rer une cl√© API
- Allez dans la section **Keys**.
- Cr√©ez une nouvelle cl√©.
- Cette cl√© sera affich√©e une seul fois **Sauvegardez la!**

---

### 3. Configurer la cl√© API dans `.env`
Dans la racine du projet, cr√©ez un fichier `.env` et ajoutez votre cl√© API :
```env
OPENROUTER_API_KEY="sk......"
```

---

Le fichier `ai_question_generator/config_ai.py` charge automatiquement ces variables d‚Äôenvironnement.

## 4. Utilisation d‚ÄôOpenRouter et choix des mod√®les
Le projet utilise **[OpenRouter](https://openrouter.ai/)** pour interagir avec des mod√®les de langage (**LLM**) h√©berg√©s dans le cloud.  
OpenRouter sert de **passerelle** vers plusieurs fournisseurs (Mistral, OpenAI, Anthropic, Meta, etc.) et permet de changer de mod√®le sans modifier le code.

### Choix des mod√®les
Pour ce projet, nous avons retenu :

**Mod√®les gratuits** :
- `mistralai/mistral-7b-instruct:free` 

**Mod√®les payants avec quota gratuit** :
- `mistralai/mistral-7b-instruct-v0.3` 

> **Remarque** : OpenRouter offre un **quota gratuit quotidien**.  
> Quand celui-ci est √©puis√©, vous pouvez :
> - Attendre le lendemain pour r√©cup√©rer le quota gratuit.
> - Utiliser un **mod√®le payant** (souvent avec un quota gratuit initial, puis facturation √† l‚Äôusage).
> - Pour changer le mod√®le, allez √† `ai_question_generator/config_ai.py` :
```python
OPENROUTER_MODEL = "mistralai/mistral-7b-instruct:free" #ICI
# Alternative: "mistralai/mistral-7b-instruct-v0.3" (payant)
```
---
## 5. Lancer l‚Äôapplication

Une fois toutes les √©tapes ci-dessus termin√©es, vous pouvez lancer l‚Äôapplication :
```bash
python run.py
```

 Assurez-vous que :
- **Ollama** est d√©marr√© (`ollama serve`)
- **Le mod√®le Mistral** est d√©j√† t√©l√©charg√©
- **Le fichier `.env`** contient les bonnes cl√©s API

---

# eval
